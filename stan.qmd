---
title: "stan"
format:
  html:
    df-print: paged
    toc: true
---

## Stan ecosystem

-   <https://mc-stan.org/>

    -   [RStan](https://mc-stan.org/users/interfaces/rstan.html)

    -   [CmdStanR](https://mc-stan.org/cmdstanr)

    -   [RStanArm](https://mc-stan.org/users/interfaces/rstanarm.html)

    -   [brms](https://mc-stan.org/users/interfaces/brms.html) \[<https://github.com/paul-buerkner/brms>\]

    -   [ShinyStan](https://mc-stan.org/users/interfaces/shinystan.html)

    -   [posterior](https://mc-stan.org/posterior/)

    -   [bayesplot](https://mc-stan.org/users/interfaces/bayesplot.html)

    -   [loo](https://mc-stan.org/users/interfaces/loo.html)

-   [bayestestR](https://easystats.github.io/bayestestR/)

-   [rethinking](https://github.com/rmcelreath/rethinking)

-   [tidybayes](https://mjskay.github.io/tidybayes/)

## Setup environment

```{r}
#| output: false
library(tidyverse)
library(rstan)
library(cmdstanr)
library(rethinking)
library(brms)
library(posterior)
library(bayesplot)
library(loo)
library(shinystan)
library(bayestestR)
library(tidybayes)
library(tidybayes.rethinking) # mjskay/tidybayes.rethinking
library(performance)
library(parameters)
library(broom)
library(broom.mixed)
library(modelsummary)
library(marginaleffects)
library(ggeffects)
library(ggformula)
library(skimr)

options(mc.cores = parallel::detectCores(), brms.backend = "cmdstanr")

rstan_options(auto_write = TRUE)
rstan_options(threads_per_chain = 1)

check_cmdstan_toolchain(fix = TRUE, quiet = TRUE)
register_knitr_engine(override = FALSE)

theme_set(theme_bw())
```

## Specify and fit model and summarize posterior

```{cmdstan output.var="m1"}
data {
  int<lower=0> N;
  array[N] int<lower=0, upper=1> y;
}

parameters {
  real<lower=0, upper=1> theta;
}

model {
  theta ~ beta(1, 1);   // uniform prior on interval 0,1
  y ~ bernoulli(theta); // likelihood
}
```

```{r}
y <- c(0, 1, 0, 0, 0, 0, 0, 0, 0, 1)

d <- list(N = length(y), y = y)
```

```{r}
#| output: false
m1$sample(data = d) |> as_draws() |> mcmc_combo()
```

```{r}
#| output: false
m2 <- ulam(
  alist(
    theta ~ dbeta(1, 1),
    y ~ dbern(theta)
), data = list(y = y), chains = 4, cores = 4)

summary(m2)
```

```{r}
extract.samples(m2) |> as_draws() |> mcmc_combo()
```

```{r}
#| output: false
m3 <- brm(y ~ NULL, family = "bernoulli", data = d)
```

```{r}
mcmc_combo(m3)
```

## Statistical rethinking

```{r}
grid_size        <- 100
p_grid           <- seq(from = 0, to = 1, length.out = grid_size)
prior            <- dbinom(x = 2, size = 9, prob = p_grid)
likelihood       <- dbinom(x = 6, size = 9, prob = p_grid)
unstd.posterior  <- likelihood * prior
posterior        <- unstd.posterior / sum(unstd.posterior)
```

What I did above is the following: I throw the globe of the earth nine times. I’m assuming the probability W/L equals 2/9. This is my prior probability. When I observe the data I see that the proportion of W/L from my experiment is 6/9. These are my experimental observations. I then calculate what the conditional probability is — given my conviction and the data I have observed.

```{r}
gf_line(prior ~ p_grid, color = "orange") |>
  gf_line(likelihood ~ p_grid, color = "skyblue") |>
  gf_line(posterior ~ p_grid, color = "red")
```

```{r}
gf_dist("beta", shape1 = 1, shape2 = 1)

globe.1 <- quap(
  alist(
    W ~ dbinom(W+L, p) , # binomial likelihood
    p ~ dunif(0, 1)      # uniform prior [0,1]
  ),
  data = list(W = 6, L = 3))

precis(globe.1)
```

```{r}
gf_dist("beta", shape1 = 2, shape2 = 7, color = "orange")

globe.2 <- quap(
  alist(
    W ~ dbinom(W+L, p), # binomial likelihood
    p ~ dbeta(2, 7)     # beta prior - [ 2W & 7L ]
  ),
  data = list(W = 6, L = 3))

precis(globe.2)
```

```{r}
nsamples   <- 10000
prior      <- extract.prior(globe.1, nsamples)
posterior  <- extract.samples(globe.1, nsamples)
```

```{r}
gf_density(~ prior$p, fill = "orange") |>
  gf_density(~ posterior$p, fill = "red")
```

## Bayesian data analysis with R and Stan: A hands-on approach

<https://baotramduong.medium.com/bayesian-data-analysis-with-r-and-stan-a-hands-on-approach-9f2ed6e3f94b>

Bayesian Data Analysis is an approach to statistical modeling and inference based on Bayes’ theorem. It involves updating probability estimates for hypotheses as new data becomes available. R and Stan are commonly used tools for Bayesian Data Analysis.

### Step 1: Build simple Bayesian model in Stan

First, let’s define a simple Bayesian model in Stan. For this example, we’ll use a normal distribution to model a set of observations.

```{stan output.var="stan_model"}
data {
  int<lower=0> N;       // Number of observations
  array[N] real y;      // Observations
  
}

parameters {
  real mu;              // Mean parameter
  real<lower=0> sigma;  // Standard deviation parameter
}

model {
  y ~ normal(mu, sigma);  // Likelihood
  // Priors can be added here if needed
}
```

In this model, `mu` is the mean parameter, `sigma` is the standard deviation parameter, and `y` represents the observed data. The model assumes a normal distribution for the likelihood.

### Step 2: Fit the Stan model and summarize results

Now, let’s move to the R code that compiles the Stan model, samples from the posterior distribution, and summarizes the results.

This code assumes that you have some observed data stored in the `data` vector.

```{r}
#| output: false

# Generate some example data
data <- rnorm(100, mean = 5, sd = 2)

# Create a list of data for Stan
stan_data <- list(N = length(data), y = data)

# Sample from the posterior
stan_samples <- sampling(stan_model, data = stan_data, chains = 4, iter = 2000)

# Summarize posterior samples
summary(stan_samples)
```

### Step 3: Visualize posterior distributions

Now, let’s visualize the posterior distributions using the `bayesplot` package.

```{r}
# Visualize posterior distributions
mcmc_trace(stan_samples)
mcmc_dens(stan_samples)
```

These plots provide insights into the behavior of the Markov Chain Monte Carlo (MCMC) chains and the marginal posterior distributions of the parameters.

### Step 4: Using the `brms` package for Bayesian regression

Next, let’s fit a Bayesian regression model using the `brms` package.

This example fits a simple Bayesian regression model with a normal distribution assumption for the response variable `y` based on predictor variable `x`.

```{r}
# Create a data frame with predictor and response variables
df <- data.frame(y = data, x = rnorm(100))

# Fit a Bayesian regression model
brm_model <- brm(y ~ x, data = df)

# Summarize the model
summary(brm_model)

# Plot posterior predictions
pp_check(brm_model)
```

### Step 5: Leave-one-out cross-validation (LOO-CV)

Now, let’s perform Leave-One-Out Cross-Validation (LOO-CV) using the `loo` package.

```{r}
# Compute LOO-CV for the model
loo_result <- loo(stan_samples, pars = "lp__")

# Display LOO-CV diagnostics
loo_result
```

LOO-CV helps assess the predictive performance of the model by comparing its performance on held-out data.

### Step 6: Visualizing Bayesian model predictions

Finally, let’s simulate and visualize Bayesian model predictions.

```{r}
# Extract posterior samples
posterior_samples <- as.matrix(stan_samples)

# Simulate predictions
simulated_predictions <- vector("list", 1000)
for (i in 1:1000) {
  simulated_predictions[[i]] <- rnorm(n = length(data), mean = posterior_samples[i, "mu"], sd = posterior_samples[i, "sigma"])
}

# Plot observed data and simulated predictions
plot(data, col = "black", pch = 16, ylim = c(min(unlist(simulated_predictions)), max(unlist(simulated_predictions))))

for (i in 1:1000) {
 lines(simulated_predictions[[i]], col = "gray", lty = 1, lwd = 0.1)
}
```

This code simulates model predictions from the posterior distribution and visualizes them alongside the observed data.

These steps provide a comprehensive overview of Bayesian Data Analysis, from specifying a simple model in Stan to performing posterior analysis and visualizing results in R. Adjust the code based on your specific modeling needs and data.

### Best practices

-   **Start Simple:** Begin with simple models and gradually move to more complex ones.

-   **Visualize:** Use diagnostic plots to assess the convergence and performance of the MCMC chains.

-   **Prior Sensitivity Analysis:** Explore how different prior choices impact the results.

-   **Model Comparison:** Consider model comparison techniques such as the Leave-One-Out Cross-Validation (LOO-CV) for model selection.

Bayesian Data Analysis with R and Stan provides a powerful and flexible framework for statistical modeling and inference. It is widely used in various fields, including biology, epidemiology, finance, and more. Understanding the principles of Bayesian inference and the practical aspects of implementing models in Stan can open up new possibilities for data analysis.

## Bayesian data analysis in R

<https://marissabarlaz.github.io/portfolio/bayesian/>
